{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5da0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "790f94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# This solves this issue: \"RuntimeError: MPS backend out of memory\" when sending vgg19 to device\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633e729",
   "metadata": {},
   "source": [
    "# Models and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e29191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Params and Hyper Parameters:\n",
    "hidden_sizes:tuple = (2048, 512)\n",
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "folds = 5\n",
    "\n",
    "use_gpu_if_available = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429f7c6",
   "metadata": {},
   "source": [
    "## Custom NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c21e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hidden_layers(hidden_sizes:tuple[int]):\n",
    "    hidden_layers = []\n",
    "\n",
    "    before_size = hidden_sizes[0]\n",
    "\n",
    "    for hidden_size in hidden_sizes[1:]:\n",
    "        hidden_layers += [\n",
    "            nn.Linear(in_features=before_size, out_features=hidden_size) ,\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        before_size = hidden_size\n",
    "\n",
    "    return hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec183003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html \n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size:int, hidden_sizes:tuple[int], output_size:int):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            *build_hidden_layers(hidden_sizes),\n",
    "            nn.Linear(hidden_sizes[-1], output_size),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        # x = self.flatten(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a93885",
   "metadata": {},
   "source": [
    "## VGG Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a9f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg19_model(input_size:int, hidden_sizes:tuple[int], output_size:int, use_batch_normalization: bool, use_imagenet_weights:bool):\n",
    "    import torchvision.models as models\n",
    "\n",
    "    model = models.vgg19_bn if use_batch_normalization else models.vgg19\n",
    "\n",
    "    vgg19 = model(\n",
    "        # If weights is None, this needs to be true:\n",
    "        init_weights = not use_imagenet_weights, \n",
    "        weights = \"IMAGENET1K_V1\" if use_imagenet_weights else None,\n",
    "\n",
    "        # num_classes is ignored if we specify a classifier below:\n",
    "        num_classes=output_size,\n",
    "    )\n",
    "\n",
    "    # modify the final fully connected layer to get binary classification:\n",
    "    # num_features = vgg19.classifier[6].in_features\n",
    "    # vgg19.classifier[6] = torch.nn.Linear(num_features, output_size)\n",
    "\n",
    "    # vgg19.avgpool= nn.AdaptiveAvgPool2d(output_size=(2, 2))\n",
    "\n",
    "    # vgg19.classifier = nn.Sequential(\n",
    "    #     # 6 divisor is a magic number, literally:\n",
    "    #     nn.Linear(in_features=int(input_size / 6) , out_features=hidden_sizes[0]) ,\n",
    "    #     nn.ReLU(),\n",
    "\n",
    "    #     *build_hidden_layers(hidden_sizes),\n",
    "        \n",
    "    #     nn.Dropout(p=0.6),  # Do we need this here? 0.5 by default\n",
    "            \n",
    "    #     nn.Linear(in_features=hidden_sizes[-1] , out_features=output_size),\n",
    "    #     # nn.LogSoftmax(dim=1)  \n",
    "    # )\n",
    "\n",
    "    return vgg19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e2395",
   "metadata": {},
   "source": [
    "## Running images on non-CPU:\n",
    "\n",
    "Mac:\n",
    "Run `brew install libjpeg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17971498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Init a device with cuda or mps so that it can train faster\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "device: Literal['cuda'] | Literal['mps'] | Literal['cpu'] = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "device = device if use_gpu_if_available else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a90ff84",
   "metadata": {},
   "source": [
    "# Run Training and Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c90b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from time import time\n",
    "\n",
    "\n",
    "def run_training(\n",
    "        dataset_loader:DataLoader,\n",
    "        model: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        epochs:int\n",
    "        ):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_accuracies = []\n",
    "    losses = []\n",
    "\n",
    "    start_time = time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Pass data to model:\n",
    "        number_of_samples = len(dataset_loader)\n",
    "        counter = 1\n",
    "        for train_x, train_y in dataset_loader:\n",
    "            print(f\"Training {counter} of {number_of_samples}, epoch {epoch}\")\n",
    "            counter += 1\n",
    "            train_x = train_x.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(train_x)\n",
    "            loss = criterion(outputs, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += train_y.size(0)\n",
    "            correct += (predicted == train_y).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        loss = running_loss / len(dataset_loader)\n",
    "        losses.append(loss)\n",
    "\n",
    "        train_accuracy = (correct / total) * 100\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}, Train Accuracy: {train_accuracy:.2f}%. Took {time()-start_time} seconds')\n",
    "        \n",
    "        start_time = time()\n",
    "\n",
    "    return train_accuracies, losses\n",
    "\n",
    "def run_test(test_loader: DataLoader, model: nn.Module,):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_x, test_y in test_loader:\n",
    "            test_x = test_x.to(device)\n",
    "            test_y = test_y.to(device)\n",
    "\n",
    "            outputs = model(test_x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += test_y.size(0)\n",
    "            correct += (predicted == test_y).sum().item()\n",
    "    \n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\\n\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f59bc33",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./dataset_load.py\n",
    "\n",
    "is_load_from_csv = input(\"Load from CSV or images directly? Type anything to load csv, leave blank for images.\")\n",
    "\n",
    "if is_load_from_csv: dataset = load_from_csv(device) # type: ignore\n",
    "else: dataset = load_from_images(device) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = dataset[0][0].numel()\n",
    "\n",
    "print(number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52710dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(dataset.classes)\n",
    "print(\"Number of classes:\", number_of_classes, dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe5f75",
   "metadata": {},
   "source": [
    "# K-Fold and running the training and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3248a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_accuracies = [0.0]*folds\n",
    "kfold = KFold(n_splits=folds, shuffle=True)\n",
    "fold = 1\n",
    "colors = 'bgcmk'\n",
    "for train_idx, test_idx in kfold.split(dataset):\n",
    "    print(f\"Fold {fold}. Training samples {len(train_idx)}, Testing samples {len(test_idx)}\")\n",
    "    \n",
    "    fold_index = fold-1\n",
    "\n",
    "    # Init a fresh model\n",
    "    # model = NeuralNetwork(\n",
    "    #     input_size=number_of_features, \n",
    "    #     hidden_size=hidden_size, \n",
    "    #     output_size=num_classes\n",
    "    # )\n",
    "    model = get_vgg19_model(\n",
    "        input_size=number_of_features, \n",
    "        hidden_sizes=hidden_sizes, \n",
    "        output_size=number_of_classes,\n",
    "        use_batch_normalization=False,\n",
    "        use_imagenet_weights=True\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    \n",
    "    # Create train and test subsets\n",
    "    train_subset = Subset(dataset, train_idx.tolist())\n",
    "    test_subset = Subset(dataset, test_idx.tolist())\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "    train_accuracies, train_losses = run_training(\n",
    "        train_loader, \n",
    "        model, \n",
    "        optimizer, \n",
    "        epochs\n",
    "    )\n",
    "\n",
    "    test_accuracy = run_test(test_loader, model)\n",
    "\n",
    "    \n",
    "    test_accuracies[fold_index] = test_accuracy\n",
    "\n",
    "    # Plot for this fold\n",
    "    fig, left_y_axis = plt.subplots()\n",
    "    right_y_axis = left_y_axis.twinx()\n",
    "    top_x_axis = right_y_axis.twiny()\n",
    "\n",
    "    left_y_axis.plot(range(1, epochs + 1), train_losses, colors[fold_index]+'-',  label=f'Fold {fold} Train Loss')\n",
    "\n",
    "    top_x_axis.plot(fold, test_accuracy, colors[fold_index]+'o', label=f'Fold {fold} Test Accuracy')\n",
    "\n",
    "    right_y_axis.plot(range(1, epochs + 1), train_accuracies, colors[fold_index]+'--', label=f'Fold {fold} Train Accuracy')\n",
    "\n",
    "    plt.title('Training Loss and Accuracy Per Fold')\n",
    "\n",
    "    left_y_axis.set_xlabel('Epoch')\n",
    "    left_y_axis.set_ylabel('Loss')\n",
    "\n",
    "    right_y_axis.set_ylabel('Accuracy (%)')\n",
    "    right_y_axis.set_ylim(50.0, 100.5)\n",
    "\n",
    "    top_x_axis.set_xlim(0, folds+1)\n",
    "    top_x_axis.set_xticks(range(folds+1))\n",
    "    top_x_axis.set_xlabel(\"Fold Number\")\n",
    "    fig.legend( bbox_to_anchor=(0.9,0.1))\n",
    "    fig.savefig(f'training_loss_fold{fold}.png', bbox_inches='tight') \n",
    "\n",
    "    fold += 1\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter([f+1 for f in range(folds)], test_accuracies, color='purple', s=100, label='Test Accuracy')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlim(0, folds+1)\n",
    "plt.xticks(range(folds+1))\n",
    "\n",
    "plt.title('Test Accuracy Per Fold')\n",
    "\n",
    "plt.savefig('test_accuracy.png', bbox_inches='tight') \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
